{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"En clair.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1vLHK2Q9i7iXN4GLODhkjziSSFJUBqU-I","timestamp":1523286126921}],"collapsed_sections":["0JQQGDIREqpA","DVPoew9jz6fT","k61aLiuIP8BJ"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"nAvD9AbQ7ifo","colab_type":"text"},"cell_type":"markdown","source":["# IMPORTS"]},{"metadata":{"id":"Z7FX9YGt7T4a","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"d4123e31-0072-4ea9-f47b-6480c5550a02","executionInfo":{"status":"ok","timestamp":1523965702437,"user_tz":-120,"elapsed":14739,"user":{"displayName":"Antoine Zyxado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102674204708073293192"}}},"cell_type":"code","source":["#INSTALLATIONS\n","!pip install -q keras\n","import keras\n","!pip install -q tqdm\n","import tqdm\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","\n","#LE FUTUR WESH\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","#CLASSIQUES\n","from google.colab import files, auth\n","from oauth2client.client import GoogleCredentials\n","import numpy as np\n","np.random.seed(1000)\n","import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import timeit\n","import sklearn.metrics as sklm\n","import copy\n","import types as python_types\n","import warnings\n","\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print('ATTENTION ! PAS DE GPU !')\n","else:\n","  print('Found GPU at: {}'.format(device_name))\n","\n","#KERAS\n","import keras\n","from keras import activations, initializers, regularizers, constraints,metrics\n","from keras.legacy import interfaces\n","from keras.engine import InputSpec, Layer\n","from keras.layers import Input,BatchNormalization\n","from keras.layers.core import Reshape, Dense, Dropout, Flatten\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import Conv2D, UpSampling2D, MaxPooling2D\n","from keras.models import Model, Sequential\n","from keras.datasets import mnist\n","from keras.optimizers import Adam, Adagrad\n","from keras import backend as K\n","K.set_image_dim_ordering('tf')\n","from keras.utils import np_utils\n","from keras.utils.generic_utils import func_dump, func_load, deserialize_keras_object\n","\n","# DRIVE AUTHENTIFICATION\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"zwA2Q_5nObOY","colab_type":"text"},"cell_type":"markdown","source":["# CONSTANTES"]},{"metadata":{"id":"KpMFPeUSKcP-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# QUELQUES VARIABLES\n","\n","adagrad = Adagrad(lr=0.001, epsilon=None, decay=0.0) #c'est celui-là qui est utilisé pour tous les modèles\n","adam = Adam(lr=0.0002, beta_1=0.5)\n","\n","randomVectorSize = 100\n","\n","d_losses = []\n","g_losses = []\n","c_losses = []\n","r_losses = []\n","\n","# Nombre de learning steps par batch du DISCRIMINATOR\n","nb_step_discriminator = 1\n","\n","# Seuil de score du DISCRIMINATOR en deça duquel on considere un exemple fake comme exemple classe 1 du REJECTOR\n","seuil_rejet_RejectionTraining = 0.45\n","\n","# Seuil de score du DISCRIMINATOR au-delà duquel on considere un exemple fake comme exemple classe 0 du REJECTOR\n","seuil_accept_RejectionTraining = 0.55\n","\n","# Nombre maximum d'exemples dans allGeneratedSamples\n","max_GeneratedSamples = 20000\n","\n","# Permutation aléatoire des exemples dans allGeneratedSamples lorsque max_GeneratedSamples exemples est atteint\n","randomPermut_GeneratedSamples = True\n","\n","# Tri des exemples dans allGeneratedSamples en fonction de leurs scores\n","sort_GeneratedSamples = False\n","\n","# Cible des exemples negatifs \n","target_neg = int(0)\n","\n","# Cible des exemples positifs \n","target_pos = int(1)\n","\n","#Seuil à appliquer pour les prédictions du REJECTOR\n","seuil_rejector = 0.5\n","\n","#Seuil à appliquer aux sorties du REJECTOR lors de l'entraînement du CLASSIFIER\n","seuil_rejector_to_train_classifier = 0.0\n","\n","# Taux de decroisance de la variance des rbf units\n","Decrease_rate_alpha = 1.1  \n","\n","# Utilisation des données perturbées\n","usePerturbatedData = False\n","\n","# Nombre de classes dans MNIST\n","nb_classes = 10\n","\n","# Choix des classes à traiter par le réseau\n","classes_train = np.random.choice(range(nb_classes), size=3, replace=False)\n","classes_train =[0, 4, 7]\n","classes_not_train = [i for i in range(nb_classes) if i not in classes_train]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3_yGMLAQClSn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# IMPORTATION MNIST\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = (X_train.astype(np.float32).reshape((X_train.shape[0],28,28,1)) - 127.5)/127.5\n","Y_train = np_utils.to_categorical(y_train, nb_classes)\n","#Y_train = Y_train * 0.9\n","X_test = (X_test.astype(np.float32).reshape((X_test.shape[0],28,28,1)) - 127.5)/127.5\n","Y_test = np_utils.to_categorical(y_test, nb_classes)\n","#Y_test = Y_test * 0.9\n","\n","indices = np.where(np.isin(y_train, classes_train))\n","X_train_restricted = X_train[indices,:]\n","X_train_restricted = X_train_restricted.reshape(X_train_restricted.shape[1],28,28,1)\n","Y_train_restricted = Y_train[indices,:]\n","\n","indices = np.where(np.isin(y_train, classes_not_train))\n","X_train_out = X_train[indices,:]\n","X_train_out = X_train_out.reshape(X_train_out.shape[1],28,28,1)\n","Y_train_out = Y_train[indices,:]\n","\n","indices = np.where(np.isin(y_test, classes_train))\n","X_test_restricted = X_test[indices,:]\n","X_test_restricted = X_test_restricted.reshape(X_test_restricted.shape[1],28,28,1)\n","Y_test_restricted = Y_test[indices,:]\n","\n","indices = np.where(np.isin(y_test, classes_not_train))\n","X_test_out = X_test[indices,:]\n","X_test_out = X_test_out.reshape(X_test_out.shape[1],28,28,1)\n","Y_test_out = Y_test[indices,:]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CqhQt-zg9CX-","colab_type":"text"},"cell_type":"markdown","source":["# FONCTION UTILITAIRES"]},{"metadata":{"id":"YnkhTU9v9Jkf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title CALCUL DE PERFORMANCES\n","###________FONCTIONS POUR CALCULER LES PERFORMANCES________###\n","\n","#MOYENNE DES PREDICTIONS CORRECTES\n","def mean_pred_pos(y_true, y_pred):\n","  good_examples = np.where(y_true[:,0] ==0)\n","  return K.mean(y_pred[good_examples])\n","  \n","#MOYENNE DES PREDICTIONS FAUSSES\n","def mean_pred_neg(y_true, y_pred):\n","  good_examples = np.where(y_true[:,0] ==1)\n","  return K.mean(y_pred)\n","\n","#RECALL RATE (vrais positifs / (vrais positifs + faux négatifs))\n","def recall(y_true, y_pred):\n","  res  = K.eval(tf.multiply (y_true, y_pred))\n","  true_positives = np.sum(np.round(np.clip(res, 0, 1)))\n","  possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n","  recall = true_positives / (possible_positives + K.epsilon())\n","  return recall\n","\n","#PRECISION (vrais positifs / (vrais positifs + faux positifs))\n","def precision(y_true, y_pred):\n","  res  = K.eval(tf.multiply (y_true, y_pred))\n","  true_positives = np.sum(np.round(np.clip(res, 0, 1)))\n","  predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n","  precision = true_positives / (predicted_positives + K.epsilon())\n","  return precision\n","\n","#F1 = moyenne harmonique du recall rate et de la précision\n","def f1(y_true, y_pred):\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall))\n","\n","#AREA UNDER CURVE de la courbe Faux positifs/Vrais positifs...\n","def auc(y_true, y_pred):  \n","  fpr, tpr, thresholds = sklm.roc_curve(y_true, y_pred, pos_label=1)\n","  return sklm.auc(fpr, tpr)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nLgrEQe8DXFQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title COUCHES RBF\n","###________TROIS CLASSES POUR IMPLEMENTER DES COUCHES RBF________###\n","\n","class RBFLayer(Layer):\n","    def __init__(self, alpha=1000.0, alpha_initializer='zeros',\n","                 alpha_regularizer=None,\n","                 alpha_constraint=None, \n","                 **kwargs):\n","        super(RBFLayer, self).__init__(**kwargs)\n","        self.supports_masking = True\n","        self.supports_masking = True\n","        self.alpha_initializer = keras.initializers.Constant(value=1000.0)\n","        self.alpha_regularizer = regularizers.get(alpha_regularizer)\n","        self.alpha_constraint = constraints.get(alpha_constraint)\n","        self.alpha = self.add_weight(shape=(1,),\n","                                     name='alpha',\n","                                     initializer=self.alpha_initializer,\n","                                     regularizer=self.alpha_regularizer,\n","                                     constraint=self.alpha_constraint)\n","        self.trainable = False\n","\n","    def call(self, inputs):\n","        y = - inputs / self.alpha[0]\n","        y = keras.backend.exp(y)\n","        return y\n","\n","    def get_config(self):\n","        config = {\n","            'alpha_initializer': initializers.serialize(self.alpha_initializer),\n","            'alpha_regularizer': regularizers.serialize(self.alpha_regularizer),\n","            'alpha_constraint': constraints.serialize(self.alpha_constraint),\n","            'shared_axes': self.shared_axes\n","        }\n","        base_config = super(RBFLayer, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","class RBF(Layer):\n","    @interfaces.legacy_dense_support\n","    def __init__(self, units,\n","                 activation=None,\n","                 use_bias=False,\n","                 kernel_initializer='TruncatedNormal',\n","                 bias_initializer='zeros',\n","                 kernel_regularizer=None,\n","                 bias_regularizer=None,\n","                 activity_regularizer=None,\n","                 kernel_constraint=None,\n","                 bias_constraint=None,\n","                 sigma = 1000.0,\n","                 **kwargs):\n","        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n","            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n","        super(RBF, self).__init__(**kwargs)\n","        self.units = units\n","        self.activation = activations.get(activation)\n","        self.use_bias = use_bias\n","        self.kernel_initializer = initializers.get(kernel_initializer)\n","        self.bias_initializer = initializers.get(bias_initializer)\n","        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","        self.bias_regularizer = regularizers.get(bias_regularizer)\n","        self.activity_regularizer = regularizers.get(activity_regularizer)\n","        self.kernel_constraint = constraints.get(kernel_constraint)\n","        self.bias_constraint = constraints.get(bias_constraint)\n","        self.sigma = sigma\n","        self.input_spec = InputSpec(min_ndim=2)\n","        self.supports_masking = True\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) >= 2\n","        input_dim = input_shape[-1]\n","\n","        self.kernel = self.add_weight(shape=(input_dim, self.units),\n","                                      initializer=self.kernel_initializer,\n","                                      name='kernel',\n","                                      regularizer=self.kernel_regularizer,\n","                                      constraint=self.kernel_constraint)\n","        if self.use_bias:\n","            self.bias = self.add_weight(shape=(self.units,),\n","                                        initializer=self.bias_initializer,\n","                                        name='bias',\n","                                        regularizer=self.bias_regularizer,\n","                                        constraint=self.bias_constraint)\n","        else:\n","            self.bias = None\n","        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n","        self.built = True\n","\n","    def call(self, inputs):\n","        norm_x = K.transpose(K.sum(inputs * inputs , axis=1))\n","        norm_w = K.sum(self.kernel *self.kernel , axis=0)\n","        norm_x = keras.backend.expand_dims(norm_x, axis=-1)\n","        prod_scal = -2 * K.dot(inputs, self.kernel)\n","        print (\"Shapes : \", norm_x.shape, norm_w.shape, prod_scal.shape) \n","        a = tf.add(norm_x, prod_scal) # -2 *  prod_scal)\n","        y = tf.add(a, norm_w )\n","        y = - y / self.sigma\n","        y = keras.backend.exp(y)\n","        return y\n","\n","    def compute_output_shape(self, input_shape):\n","        assert input_shape and len(input_shape) >= 2\n","        assert input_shape[-1]\n","        output_shape = list(input_shape)\n","        output_shape[-1] = self.units\n","        return tuple(output_shape)\n","\n","    def get_config(self):\n","        config = {\n","            'units': self.units,\n","            'activation': activations.serialize(self.activation),\n","            'use_bias': self.use_bias,\n","            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","            'bias_initializer': initializers.serialize(self.bias_initializer),\n","            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n","            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n","            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n","            'bias_constraint': constraints.serialize(self.bias_constraint)\n","        }\n","        base_config = super(RBF, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n","\n","class RBF2(Layer):\n","    @interfaces.legacy_dense_support\n","    def __init__(self, units,\n","                 activation=None,\n","                 use_bias=False,\n","                 kernel_initializer='TruncatedNormal',\n","                 bias_initializer='zeros',\n","                 kernel_regularizer=None,\n","                 bias_regularizer=None,\n","                 activity_regularizer=None,\n","                 kernel_constraint=None,\n","                 bias_constraint=None,\n","                 **kwargs):\n","        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n","            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n","        super(RBF2, self).__init__(**kwargs)\n","        self.units = units\n","        self.activation = activations.get(activation)\n","        self.use_bias = use_bias\n","        self.kernel_initializer = initializers.get(kernel_initializer)\n","        self.bias_initializer = initializers.get(bias_initializer)\n","        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","        self.bias_regularizer = regularizers.get(bias_regularizer)\n","        self.activity_regularizer = regularizers.get(activity_regularizer)\n","        self.kernel_constraint = constraints.get(kernel_constraint)\n","        self.bias_constraint = constraints.get(bias_constraint)\n","        self.input_spec = InputSpec(min_ndim=2)\n","        self.supports_masking = True\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) >= 2\n","        input_dim = input_shape[-1]\n","        self.kernel = self.add_weight(shape=(input_dim, self.units),\n","                                      initializer=self.kernel_initializer,\n","                                      name='kernel',\n","                                      regularizer=self.kernel_regularizer,\n","                                      constraint=self.kernel_constraint)\n","        if self.use_bias:\n","            self.bias = self.add_weight(shape=(self.units,),\n","                                        initializer=self.bias_initializer,\n","                                        name='bias',\n","                                        regularizer=self.bias_regularizer,\n","                                        constraint=self.bias_constraint)\n","        else:\n","            self.bias = None\n","        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n","        self.built = True\n","\n","    def call(self, inputs):\n","        norm_x = K.transpose(K.sum(inputs * inputs , axis=1))\n","        norm_w = K.sum(self.kernel *self.kernel , axis=0)\n","        norm_x = keras.backend.expand_dims(norm_x, axis=-1)\n","        prod_scal = -2 * K.dot(inputs, self.kernel)\n","        print (\"Shapes : \", norm_x.shape, norm_w.shape, prod_scal.shape) \n","        a = tf.add(norm_x, prod_scal) # -2 *  prod_scal)\n","        y = tf.add(a, norm_w )\n","        return y\n","\n","    def compute_output_shape(self, input_shape):\n","        assert input_shape and len(input_shape) >= 2\n","        assert input_shape[-1]\n","        output_shape = list(input_shape)\n","        output_shape[-1] = self.units\n","        return tuple(output_shape)\n","\n","    def get_config(self):\n","        config = {\n","            'units': self.units,\n","            'activation': activations.serialize(self.activation),\n","            'use_bias': self.use_bias,\n","            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n","            'bias_initializer': initializers.serialize(self.bias_initializer),\n","            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n","            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n","            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n","            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n","            'bias_constraint': constraints.serialize(self.bias_constraint)\n","        }\n","        base_config = super(RBF2, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t0_aQmwuQvdc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title AFFICHAGE\n","###________FONCTIONS D'AFFICHAGE________###\n","\n","# AFFICHAGE DES LOSS DU GAN\n","def plotLoss(epoch):\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(d_losses, label='Discriminitive loss')\n","    plt.plot(g_losses, label='Generative loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig('dcgan_loss_epoch_%d.png' % epoch)\n","    uploaded = drive.CreateFile({'title': 'dcgan_loss_epoch_%d.png' % epoch})\n","    uploaded.Upload()\n","\n","# EXEMPLES D'IMAGES GENEREES\n","def plotGeneratedImages(epoch, examples=100):\n","    noise = np.random.normal(0, 1, size=[examples, randomVectorSize])\n","    generatedImages = generator.predict(noise)\n","    generatedImages = generatedImages.reshape(examples, 28, 28)\n","    Xg = generatedImages[:8]\n","    nom_file = \"gan_generated_image_epoch_\" +str(epoch) + \".png\"\n","    print (nom_file)\n","    np.save(nom_file, Xg)\n","    files.download(nom_file)\n","\n","# EXEMPLES D'IMAGES GENEREES 2\n","def plotGeneratedImages2(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n","    noise = np.random.normal(0, 1, size=[examples, randomVectorSize])\n","    generatedImages = generator.predict(noise)\n","    plt.figure(figsize=figsize)\n","    for i in range(generatedImages.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(generatedImages[i, 0], interpolation='nearest', cmap='gray_r')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)\n","    files.download('gan_generated_image_epoch_%d.png' % epoch)    \n","\n","# AFFICHE LES IMAGES (mettez-en 100 ou moins svp sinon je sais pas ce que ça va faire)\n","def plotImages(images, dim=(10, 10), figsize=(10, 10)):\n","    plt.figure(figsize=figsize)\n","    for i in range(images.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(images[i, 0], interpolation='nearest', cmap='gray_r')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig('gan_perturbated_images.png')\n","    files.download('gan_perturbated_images.png')  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"7MatjXR7aOWd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title MISE EN FORME DE DONNEES\n","###________FONCTIONS DE MISE EN FORME DES DONNEES________###\n","\n","# MET EN FORME LES LABELS ET LES DONNEES POUR LE TEST DU CLASSIFIEUR SUR LES DONNEES NON REJETEES\n","def data_evaluation_classifier(X_real, y_real):\n","  y_dgan = rejector.predict(X_real)\n","  good_examples = np.where(y_dgan[:,0] < seuil_rejector)\n","  X_disc = X_real[good_examples]\n","  y_disc = y_real[good_examples]\n","  weights = np.ones((y_real.shape[0],1))\n","  return X_disc, y_disc\n","\n","# MET EN FORME LES LABELS POUR DES ENTREES X TOUTES VRAIES\n","def data_evaluation_rejector_true(X):\n","    return X, np.ones((X.shape[0],1))\n","\n","# MET EN FORME LES LABELS ET LES DONNEES POUR LES IMAGES GENEREES\n","def data_evaluation_rejector_fake(X_fake, filtre):\n","  if filtre:\n","    y_reject = discriminator.predict(X_fake)\n","    good_examples = np.where(y_reject[:,0] < seuil_rejet_RejectionTraining)\n","    X_disc = X_fake[good_examples]\n","    y_disc = np.zeros((X_disc.shape[0],1))\n","  else:\n","    X_disc = X_fake[:]\n","    y_disc = np.zeros((X_disc.shape[0],1))\n","  return X_disc, y_disc\n","\n","# MODIFIE DES IMAGES EN FAISANT DU COPIER/COLLER (à reprendre en modifiant)\n","def imageBatch_mix(batchsize):\n","  lesindices =  np.random.randint(0, X_train_restricted.shape[0], size=batchsize)\n","  imageBatch_to_perturb = X_train_restricted[lesindices,:]\n","  imageBatch_to_perturb = imageBatch_to_perturb.reshape((imageBatch_to_perturb.shape[0], X_train.shape[1]*X_train.shape[2]))\n","  data_dim = imageBatch_to_perturb.shape[1]\n","  X_perturbated = imageBatch_to_perturb\n","  rate1 = 0.9\n","  seuil1 = int(rate1* (float(data_dim)))\n","  seuil1 = np.random.randint(0, high=seuil1)\n","  X_perturbated[:,:seuil1] = imageBatch_to_perturb[:,:seuil1]\n","  rate2 = 0.9\n","  seuil2 = int(rate2* (float(data_dim)))\n","  seuil2 = np.random.randint(0, high=seuil2)\n","  seuil2 = min(seuil1+seuil2, data_dim)\n","  p = np.random.permutation(batchsize)\n","  X_perturbated[:,seuil1:seuil2] = imageBatch_to_perturb[p,seuil1:seuil2]\n","  p = np.random.permutation(batchsize)  \n","  X_perturbated[:,seuil2:] = imageBatch_to_perturb[p,seuil2:]\n","  X_perturbated = X_perturbated.reshape((imageBatch_to_perturb.shape[0], 28, 28, 1))\n","  return X_perturbated\n","\n","# RENVOIE UN BATCH D'ENTRAINEMENT POUR LE REJECTOR\n","def data_train_rejector(X_real, y_real, X_fake, X_perturbated):\n","    batchSize = X_real.shape[0]\n","    y_fake_reject = discriminator.predict(X_fake)\n","    good_examples = np.where(y_fake_reject[:,0] < seuil_rejet_RejectionTraining )\n","    bad_examples = np.where(y_fake_reject[:,0] > seuil_accept_RejectionTraining )\n","    X_fake_good = X_fake[good_examples[0]]\n","    X_fake_good= X_fake_good[:min(X_fake_good.shape[0],batchSize)]\n","    y_fake_good = np.zeros((y_fake_reject[good_examples[0]].shape[0],1))\n","    y_fake_good= y_fake_good[:min(X_fake_good.shape[0],batchSize)]\n","    y_fake_good[:,] = 0\n","    X_fake_bad = X_fake[bad_examples[0]]\n","    X_fake_bad = X_fake_bad[:min(X_fake_bad.shape[0],batchSize)]\n","    y_fake_bad = np.zeros((y_fake_reject[bad_examples[0]].shape[0],1))\n","    y_fake_bad = y_fake_bad[:min(X_fake_bad.shape[0],batchSize)]\n","    y_fake_bad[:,] = 1\n","    y_real_reject = np.ones((X_real.shape[0],1))\n","    y_perturbated = np.zeros((X_perturbated.shape[0],1))\n","    if usePerturbatedData:\n","      X = np.concatenate([X_real, X_fake_good, X_fake_bad, X_perturbated])\n","      y_rejection = np.concatenate([y_real_reject, y_fake_good, y_fake_bad, y_perturbated])\n","    else:\n","      X = np.concatenate([X_real, X_fake_good, X_fake_bad])   \n","      y_rejection = np.concatenate([y_real_reject, y_fake_good, y_fake_bad])\n","    weights = np.ones((y_rejection.shape[0],1))\n","    return X, y_rejection, weights\n","\n","# RENVOIE LES ELEMENTS DE X_REAL NON REJETES PAR LE REJECTOR (à modifier pour inclure les données perturbées)\n","def data_train_classifier(X_real, y_real, X_perturbated):\n","    y_dgan = rejector.predict(X_real)\n","    good_examples = np.where(y_dgan[:,0] > seuil_rejector_to_train_classifier)\n","    X_disc = X_real[good_examples]\n","    y_disc = y_real[good_examples]\n","    weights = np.ones((y_disc.shape[0],1))\n","    \"\"\"\n","    y_perturbated = np.zeros((X_perturbated.shape[0],y_disc.shape[1]))\n","    X = np.concatenate([X_disc, X_perturbated])\n","    y = np.concatenate([y_disc, y_perturbated])\n","    weights = np.ones((y.shape[0],1))\n","    \"\"\"\n","    return X_disc, y_disc, weights\n","\n","#APPLIQUE UNE PERMUTATION DES IMAGES GENEREES (optionnel) PUIS FILTRE LES IMAGES EN FONCTION DE LEUR REPONSE AU DISCRIMINATEUR\n","def filtrage(allgeneratedImages, nb_generated_max = max_GeneratedSamples):\n","    if randomPermut_GeneratedSamples:\n","      p = np.random.permutation(range(allgeneratedImages.shape[0]))\n","      allgeneratedImages = allgeneratedImages[p]\n","    y_fake_reject = discriminator.predict(allgeneratedImages)\n","    good_examples = np.where(y_fake_reject[:,0] < seuil_rejet_RejectionTraining )\n","    X_temp = allgeneratedImages[good_examples]\n","    if (X_temp.shape[0]> nb_generated_max):\n","        return X_temp[:nb_generated_max]\n","    else:\n","        if (X_temp.shape[0]==0):\n","            return allgeneratedImages[:min(allgeneratedImages.shape[0],nb_generated_max)]\n","        else:\n","            return X_temp          \n","          \n","# SAUVEGARDER LES MODELES\n","def saveModels(epoch):\n","    generator.save('models/dcgan_generator_epoch_%d.h5' % epoch)\n","    discriminator.save('models/dcgan_discriminator_epoch_%d.h5' % epoch)\n","\n","# TELECHARGER LES MODELES\n","def downloadModels(epoch):\n","    uploaded = drive.CreateFile({'title': 'models/dcgan_generator_epoch_%d.h5' % epoch})\n","    uploaded.Upload()\n","    uploaded = drive.CreateFile({'title': 'models/dcgan_discriminator_epoch_%d.h5' % epoch})\n","    uploaded.Upload()\n","\n","#Je sais pas encore ni ce que c'est ni à quoi ça sert, ça ne semble pas utilisé\n","def toutes_data_evaluation_classifier(X, y):\n","  y_disc = np.concatenate((np.zeros((y.shape[0],1)), y ), axis=1)\n","  return X, y_disc\n","\n","# Ne semble pas utilisé\n","def imageBatch_neg(batchsize):\n","  lesindices =  np.random.randint(0, X_train.shape[0], size=batchsize*3)\n","  imageBatch_to_perturb = X_train[lesindices,:]\n","  X_perturbated = imageBatch_to_perturb[:batchsize] + imageBatch_to_perturb[batchsize:2*batchsize]- imageBatch_to_perturb[2*batchsize:3*batchsize]\n","  #X_perturbated = (imageBatch_to_perturb[:batchsize] + imageBatch_to_perturb[batchsize:2*batchsize])/2\n","  return X_perturbated"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0JQQGDIREqpA","colab_type":"text"},"cell_type":"markdown","source":["# MODELES"]},{"metadata":{"id":"fN5GI4c1KyOR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":496},"outputId":"c6aef69e-abc2-49eb-c121-af2b27e5a340","executionInfo":{"status":"ok","timestamp":1523965709452,"user_tz":-120,"elapsed":567,"user":{"displayName":"Antoine Zyxado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102674204708073293192"}}},"cell_type":"code","source":["# Generator\n","\n","g_input = Input(shape=(randomVectorSize,),name=\"g_input\")\n","x = Dense(7*7*128, kernel_initializer=initializers.RandomNormal(stddev=0.02))  (g_input)\n","x = LeakyReLU(0.2)                                                             (x)\n","x = Reshape((7,7,128))                                                         (x)\n","x = UpSampling2D(size=(2, 2))                                                  (x)\n","x = Conv2D(64, kernel_size=(5, 5), padding='same')                             (x)\n","x = LeakyReLU(0.2)                                                             (x)\n","x = UpSampling2D(size=(2, 2))                                                  (x)\n","g_prediction = Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh')(x)\n","\n","generator = Model(input = g_input, output = g_prediction)\n","generator.compile(optimizer=adagrad, loss='binary_crossentropy')\n","generator.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","g_input (InputLayer)         (None, 100)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 6272)              633472    \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 6272)              0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 64)        204864    \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 28, 28, 1)         1601      \n","=================================================================\n","Total params: 839,937\n","Trainable params: 839,937\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"g_..., outputs=Tensor(\"co...)`\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"metadata":{"id":"bT5meen2EsxQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":496},"outputId":"87d0ea2a-967e-4b89-aae2-929087721e52","executionInfo":{"status":"ok","timestamp":1523965710208,"user_tz":-120,"elapsed":615,"user":{"displayName":"Antoine Zyxado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102674204708073293192"}}},"cell_type":"code","source":["# Discriminator\n","\n","d_input = Input(shape=(28,28,1),name=\"d_input\")\n","x = Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02)) (d_input)\n","x = LeakyReLU(0.2)                                                 (x)\n","x = Dropout(0.3)                                                   (x)\n","x = Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n","x = LeakyReLU(0.2)                                                 (x)\n","x = Dropout(0.3)                                                   (x)\n","x = Flatten()                                                      (x)\n","d_prediction = Dense(1, activation='sigmoid', name='d_output')     (x)\n","\n","discriminator = Model(input = d_input, output = d_prediction)\n","discriminator.compile(optimizer=adagrad, loss='binary_crossentropy')\n","discriminator.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","d_input (InputLayer)         (None, 28, 28, 1)         0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 14, 14, 64)        1664      \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 7, 7, 128)         204928    \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 6272)              0         \n","_________________________________________________________________\n","d_output (Dense)             (None, 1)                 6273      \n","=================================================================\n","Total params: 212,865\n","Trainable params: 212,865\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"d_..., outputs=Tensor(\"d_...)`\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"metadata":{"id":"uce7_osINqgj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":292},"outputId":"760b7146-3b42-4dc3-e8b3-3b90130f56cb","executionInfo":{"status":"ok","timestamp":1523965711189,"user_tz":-120,"elapsed":933,"user":{"displayName":"Antoine Zyxado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102674204708073293192"}}},"cell_type":"code","source":["# GAN\n","\n","discriminator.trainable = False\n","gan_input = Input(shape=(randomVectorSize,))\n","x = generator (gan_input)\n","gan_prediction = discriminator (x)\n","\n","gan = Model(input = gan_input, output = gan_prediction)\n","gan.compile(optimizer=adagrad, loss='binary_crossentropy')\n","gan.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 100)               0         \n","_________________________________________________________________\n","model_1 (Model)              (None, 28, 28, 1)         839937    \n","_________________________________________________________________\n","model_2 (Model)              (None, 1)                 212865    \n","=================================================================\n","Total params: 1,052,802\n","Trainable params: 839,937\n","Non-trainable params: 212,865\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"mo...)`\n","  import sys\n"],"name":"stderr"}]},{"metadata":{"id":"L1b4xOugDv8V","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":496},"outputId":"c3e4f62e-a4fb-4e7a-b5b6-7b01d0561b6a","executionInfo":{"status":"ok","timestamp":1523965712564,"user_tz":-120,"elapsed":1336,"user":{"displayName":"Antoine Zyxado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102674204708073293192"}}},"cell_type":"code","source":["# Classifier\n","\n","c_input = Input(shape=(28,28,1), name='c_input')\n","x =  Conv2D(64, kernel_size=(3, 3), activation='relu') (c_input)\n","x = MaxPooling2D(pool_size=(2, 2))                     (x)\n","x = Conv2D(128, (3, 3), activation='relu')             (x)\n","x = MaxPooling2D(pool_size=(2, 2))                     (x)\n","x = Dropout(0.25)                                      (x)\n","x = Flatten()                                          (x)\n","x = Dense(128, activation='relu')                      (x)\n","#x = Dropout(0.5)                                       (x)\n","c_prediction = Dense(10, activation='softmax', name='c_output') (x)\n","\n","classifier = Model(input = c_input, output = c_prediction)\n","classifier.compile(optimizer=adagrad, loss= 'binary_crossentropy', metrics=[metrics.categorical_accuracy])\n","classifier.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","c_input (InputLayer)         (None, 28, 28, 1)         0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 26, 26, 64)        640       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 11, 11, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 3200)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               409728    \n","_________________________________________________________________\n","c_output (Dense)             (None, 10)                1290      \n","=================================================================\n","Total params: 485,514\n","Trainable params: 485,514\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"c_..., outputs=Tensor(\"c_...)`\n","  del sys.path[0]\n"],"name":"stderr"}]},{"metadata":{"id":"xieokWfyHqji","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":564},"outputId":"5c80b829-2d6c-49fe-809d-48d227a95f5f","executionInfo":{"status":"ok","timestamp":1523965713550,"user_tz":-120,"elapsed":938,"user":{"displayName":"Antoine Zyxado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102674204708073293192"}}},"cell_type":"code","source":["# Rejector\n","\n","r_input = Input(shape=(28,28,1), name='r_input')\n","x =  Conv2D(64, kernel_size=(3, 3), activation='relu')(r_input)\n","x = MaxPooling2D(pool_size=(3, 3))                    (x)\n","x = Conv2D(128, (3, 3), activation='relu')            (x)\n","x = MaxPooling2D(pool_size=(3, 3))                    (x)\n","x = Dropout(0.25)                                     (x)\n","x = Flatten()                                         (x)\n","#x = RBF(128, sigma=1000.0)                            (x)\n","x = Dense(128, activation='relu')                     (x)\n","x = RBF2(300)                                         (x)\n","x = RBFLayer(alpha=2000.0)                            (x)\n","#x = BatchNormalization()                              (x)\n","#x = Dropout(0.5)                                      (x)\n","r_prediction = Dense(1, activation='tanh', name='r_output', use_bias=False) (x)\n","\n","rejector = Model(input = r_input, output = r_prediction)\n","rejector.compile(optimizer=adagrad, loss= 'mse', metrics=['acc'])  #  metrics=['acc', f1, precision, recall])\n","rejector.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Shapes :  (?, 1) (300,) (?, 300)\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","r_input (InputLayer)         (None, 28, 28, 1)         0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 6, 6, 128)         73856     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 2, 2, 128)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               65664     \n","_________________________________________________________________\n","rb_f2_1 (RBF2)               (None, 300)               38400     \n","_________________________________________________________________\n","rbf_layer_1 (RBFLayer)       (None, 300)               1         \n","_________________________________________________________________\n","r_output (Dense)             (None, 1)                 300       \n","=================================================================\n","Total params: 178,861\n","Trainable params: 178,860\n","Non-trainable params: 1\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"r_..., outputs=Tensor(\"r_...)`\n"],"name":"stderr"}]},{"metadata":{"id":"VjfXQ5zcVWvU","colab_type":"text"},"cell_type":"markdown","source":["# TRAININGS"]},{"metadata":{"id":"5EBjYfnOVZSb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title ENTRAINEMENT DE TOUS LES RESEAUX\n","def train_all(X_train, Y_train, X_test_in, Y_test_in, X_test_out, Y_test_out, epochs=1, batchSize=128):\n","  #INITIALISATION...\n","  batchCount = int(X_train.shape[0] / batchSize)\n","  print ('Epochs:', epochs)\n","  print ('Batch size:', batchSize)\n","  print ('Batches per epoch:', batchCount)\n","  noise = np.random.normal(0, 1, size=[batchSize, randomVectorSize])\n","  allgeneratedImages = generator.predict(noise)\n","\n","  for e in range(1, epochs+1):\n","    print ('-'*15, 'Epoch %d' % e, '-'*15)\n","    rloss=0\n","    closs=0\n","    dloss=0\n","    gloss=0\n","    \n","    # ENTRAINEMENT RESEAUX\n","    for _ in tqdm(range(batchCount)):\n","      # DISCRIMINATOR\n","      noise = np.random.normal(0, 1, size=[batchSize, randomVectorSize])\n","      generatedImages = generator.predict(noise)\n","      imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n","      X = np.concatenate([imageBatch, generatedImages])\n","      yDis = np.zeros(2*batchSize)\n","      yDis[:batchSize] = 0.9\n","      dloss += discriminator.train_on_batch(X, yDis)\n","\n","      # GENERATOR\n","      noise = np.random.normal(0, 1, size=[batchSize, randomVectorSize])\n","      yGen = np.ones(batchSize)\n","      discriminator.trainable = False\n","      gloss += gan.train_on_batch(noise, yGen)\n","      \n","      # RECUPERATION DES IMAGES GENEREES PERTINENTES\n","      allgeneratedImages = np.concatenate ([allgeneratedImages, generatedImages])\n","      allgeneratedImages = filtrage(allgeneratedImages)\n","\n","      # CLASSIFIER\n","      indices = np.random.randint(0, X_train.shape[0], size=2*batchSize)\n","      imageBatch = X_train[indices,:]\n","      imageBatch_labels = Y_train[indices,:]\n","      imageBatch_perturbated = imageBatch_mix(batchSize)\n","      X_disc, y_disc, weights = data_train_classifier(imageBatch, imageBatch_labels, imageBatch_perturbated)#pour l'instant cette fonction ne prend pas en compte les données perturbées => à coder\n","      if (X_disc.shape[0]> 10):\n","        scores = classifier.train_on_batch(X_disc, y_disc)\n","        closs += scores[0]\n","\n","      # REJECTOR\n","      X_disc, y_disc, weights = data_train_rejector(imageBatch, imageBatch_labels, allgeneratedImages, imageBatch_perturbated)\n","      scores = rejector.train_on_batch(X_disc, y_disc)\n","      rloss += scores[0]\n","\n","    # TESTS ET EVALUATIONS\n","    d_losses.append(dloss)\n","    g_losses.append(gloss)\n","    r_losses.append(rloss)\n","    c_losses.append(closs)\n","\n","    X_disc, y_disc = data_evaluation_rejector_true(X_train)\n","    r_train_in = rejector.evaluate(X_disc, y_disc)\n","    X_disc, y_disc = data_evaluation_rejector_true(X_test_in)\n","    r_test_in = rejector.evaluate(X_disc, y_disc)\n","    X_disc, y_disc = data_evaluation_rejector_fake(X_test_out, filtre=False)\n","    r_test_out = rejector.evaluate(X_disc, y_disc)\n","    X_disc, y_disc = data_evaluation_rejector_fake(allgeneratedImages, filtre=True)\n","    r_generated_filtre = rejector.evaluate(X_disc, y_disc)\n","    X_disc, y_disc = data_evaluation_rejector_fake(allgeneratedImages, filtre=False)\n","    r_generated = rejector.evaluate(X_disc, y_disc)\n","    X_disc, y_disc = data_evaluation_classifier(X_test,Y_test)\n","    a_eval_pred = classifier.evaluate(X_disc, y_disc)\n","    a_pred_in = classifier.evaluate(X_test_in, Y_test_in)\n","    a_pred_out = classifier.evaluate(X_test_out, Y_test_out)\n","\n","    print (\"Nombre d'exemples générés : \", allgeneratedImages.shape[0])\n","    print (\"Score du REJECTOR sur les données d'entraînement de MNIST : \", r_train_in)\n","    print (\"Score de REJECTOR sur les données générées par le GAN : \", r_generated)\n","    print (\"Score du REJECTOR sur les données générées par le GAN filtrées : \", r_generated_filtre)\n","    print (\"Score du REJECTOR sur les données de test de MNIST des classes attendues : \", r_test_in)\n","    print (\"Score du REJECTOR sur les données de test de MNIST des classes non attendues : \", r_test_out)\n","    print (\"Score du CLASSIFIER sur les données de test de MNIST non rejetées : \", a_eval_pred)\n","    print (\"Score du CLASSIFIER sur les données de test de MNIST des classes attendues : \", a_pred_in)\n","    print (\"Score du CLASSIFIER sur les données de test de MNIST des classes non attendues : \", a_pred_out)\n","\n","    Xin,Yin = data_evaluation_rejector_true(X_test_in, Y_test_in)\n","    y_pred_in = rejector.predict(Xin)\n","    Xout,Yout = data_evaluation_rejector_fake(X_test_out, filtre=False)\n","    y_pred_out = rejector.predict(Xout)\n","    Ytrue = np.concatenate ((Yout,Yin))\n","    Ypred = np.concatenate ((y_pred_out,y_pred_in))\n","\n","    print (\"Prédictions du REJECTOR sur les données de test de MNIST des classes attendues : Min, \", np.min(y_pred_in), \" Max\", np.max(y_pred_in), ' Moyenne : ', np.mean(y_pred_in))\n","    print (\"Prédictions du REJECTOR sur les données de test de MNIST des classes non attendues : Min, \", np.min(y_pred_out), \" Max\", np.max(y_pred_out), ' Moyenne : ', np.mean(y_pred_out))\n","    print(\"Performances du REJECTOR sur toutes les données de test de MNIST :\")\n","    print (\"F1 : \", f1(Ytrue,Ypred), \"Précision : \", precision(Ytrue,Ypred), \"Recall rate : \", recall(Ytrue,Ypred))\n","    print(\" Area Under Curve : \" ,  auc(Ytrue, Ypred))\n","    print(\"\")\n","    print (\"Losses : DISCRIMINATOR \", d_losses,\" GENERATOR \", g_losses,\" CLASSIFIER \", c_losses,\" REJECTOR \", r_losses)\n","    \n","    #SAUVEGARDER ET MONTRER LES IMAGES GENEREES REGULIEREMENT\n","    if e == 1 or e % 5 == 0:\n","      plotGeneratedImages(e)\n","      saveModels(e)\n","    \n","    #MODIFICATION DU ALPHA DES RBF LAYERS\n","    b = classifier_rejection.layers[8].get_weights()\n","    alpha = b[0][0]\n","    alpha = alpha * Decrease_rate_alpha        \n","    b[0][0]=alpha\n","    rejector.layers[8].set_weights(b)\n","  plotLoss(e)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fk3QqN5dftrB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"cellView":"form"},"cell_type":"code","source":["#@title ENTRAINEMENT DU GAN SEUL (télécharge toutes les epochs)\n","def train_GAN(X_train, Y_train, epochs=1, batchSize=128):\n","  #INITIALISATION...\n","  batchCount = int(X_train.shape[0] / batchSize)\n","  print ('Epochs:', epochs)\n","  print ('Batch size:', batchSize)\n","  print ('Batches per epoch:', batchCount)\n","\n","  for e in range(1, epochs+1):\n","    print ('-'*15, 'Epoch %d' % e, '-'*15)\n","    dloss=0\n","    gloss=0\n","    for _ in tqdm(range(batchCount)):\n","      # DISCRIMINATOR\n","      noise = np.random.normal(0, 1, size=[batchSize, randomVectorSize])\n","      generatedImages = generator.predict(noise)\n","      imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n","      X = np.concatenate([imageBatch, generatedImages])\n","      yDis = np.zeros(2*batchSize)\n","      yDis[:batchSize] = 0.9\n","      dloss += discriminator.train_on_batch(X, yDis)\n","\n","      # GENERATOR\n","      noise = np.random.normal(0, 1, size=[batchSize, randomVectorSize])\n","      yGen = np.ones(batchSize)\n","      discriminator.trainable = False\n","      gloss += gan.train_on_batch(noise, yGen)\n","      \n","    # TESTS ET EVALUATIONS\n","    d_losses.append(dloss)\n","    g_losses.append(gloss)\n","    print (\"Losses : DISCRIMINATOR \", d_losses,\" GENERATOR \", g_losses)\n","    \n","    saveModels(e)\n","    downloadModels(e)\n","    plotLoss(e)\n","    \n","    #MODIFICATION DU ALPHA DES RBF LAYERS\n","    b = classifier_rejection.layers[8].get_weights()\n","    alpha = b[0][0]\n","    alpha = alpha * Decrease_rate_alpha        \n","    b[0][0]=alpha\n","    rejector.layers[8].set_weights(b)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DVPoew9jz6fT","colab_type":"text"},"cell_type":"markdown","source":["# Lancements"]},{"metadata":{"id":"ByQwwzQDROE-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":880},"outputId":"14c41fa4-5a25-4ff3-9b2c-c987bb292f8c","executionInfo":{"status":"error","timestamp":1523970189681,"user_tz":-120,"elapsed":2786522,"user":{"displayName":"Antoine Zyxado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102674204708073293192"}}},"cell_type":"code","source":["train_all(X_train, Y_train, X_test_restricted, Y_test_restricted, X_test_out, Y_test_out, epochs=1, batchSize=64)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["  0%|          | 0/937 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","  0%|          | 1/937 [00:00<02:18,  6.76it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epochs: 1\n","Batch size: 64\n","Batches per epoch: 937\n","--------------- Epoch 1 ---------------\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 937/937 [46:09<00:00,  2.96s/it]"],"name":"stderr"},{"output_type":"stream","text":[" 1440/60000 [..............................] - ETA: 6s"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["60000/60000 [==============================] - 7s 117us/step\n","2990/2990 [==============================] - 0s 115us/step\n","7010/7010 [==============================] - 1s 122us/step\n","20000/20000 [==============================] - 2s 116us/step\n","20000/20000 [==============================] - 2s 117us/step\n","681/681 [==============================] - 0s 251us/step\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4ae70a16006b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_restricted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_restricted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-dcaaad6f427d>\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(X_train, Y_train, X_test_in, Y_test_in, X_test_out, Y_test_out, epochs, batchSize)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mX_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_evaluation_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0ma_eval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_disc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0ma_pred_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0ma_pred_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1769\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking target: expected c_output to have 2 dimensions, but got array with shape (2990, 10, 1)"]}]},{"metadata":{"id":"k61aLiuIP8BJ","colab_type":"text"},"cell_type":"markdown","source":["# DERNIERS CHANGEMENTS / ETAT DES LIEUX"]},{"metadata":{"id":"hdItkPN9QCoK","colab_type":"text"},"cell_type":"markdown","source":["Ajout du code d'Artieres : TERMINE\n","\n","Test du code d'Artieres : EN COURS\n","- Entraînement : OK\n","- Tests : EN COURS\n","- Autres fonctions : A FAIRE\n","\n","Codes d'entraînement séparés : EN COURS\n","- GAN seul : A TESTER\n","- Création BDD : A FAIRE\n","- REJECTOR seul : A FAIRE\n","- CLASSIFIEUR seul : A ECRIRE (importer le modèle déjà prêt)\n","\n","Nouvelles fonctions de choix des exemples : A VENIR"]}]}